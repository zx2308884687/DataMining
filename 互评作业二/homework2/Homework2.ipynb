{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据挖掘互评作业二: 频繁模式与关联规则挖掘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github 地址：https://github.com/zx2308884687/DataMining/tree/HomeWork/%E4%BA%92%E8%AF%84%E4%BD%9C%E4%B8%9A%E4%BA%8C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 导入数据集并进行初步处理\n",
    "  使用的数据集为Wine Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./Wine Reviews/winemag-data_first150k.csv')\n",
    "df2 = pd.read_csv('./Wine Reviews/winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 合并数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150930 entries, 0 to 150929\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   points    150930 non-null  int64  \n",
      " 1   price     137235 non-null  float64\n",
      " 2   province  150925 non-null  object \n",
      " 3   region_1  125870 non-null  object \n",
      " 4   region_2  60953 non-null   object \n",
      " 5   variety   150930 non-null  object \n",
      " 6   winery    150930 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 8.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129971 entries, 0 to 129970\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   points    129971 non-null  int64  \n",
      " 1   price     120975 non-null  float64\n",
      " 2   province  129908 non-null  object \n",
      " 3   region_1  108724 non-null  object \n",
      " 4   region_2  50511 non-null   object \n",
      " 5   variety   129970 non-null  object \n",
      " 6   winery    129971 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.drop(['country', 'description', 'designation'], axis=1, inplace=True)\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "df1.info()\n",
    "df2.drop(['country', 'description', 'designation', 'taster_name', 'taster_twitter_handle', 'title'], axis=1, inplace=True)\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280901 entries, 0 to 280900\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   points    280901 non-null  int64  \n",
      " 1   price     258210 non-null  float64\n",
      " 2   province  280833 non-null  object \n",
      " 3   region_1  234594 non-null  object \n",
      " 4   region_2  111464 non-null  object \n",
      " 5   variety   280900 non-null  object \n",
      " 6   winery    280901 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df1,df2],ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 删除缺失值并重置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110996 entries, 0 to 110995\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   points    110996 non-null  int64  \n",
      " 1   price     110996 non-null  float64\n",
      " 2   province  110996 non-null  object \n",
      " 3   region_1  110996 non-null  object \n",
      " 4   region_2  110996 non-null  object \n",
      " 5   variety   110996 non-null  object \n",
      " 6   winery    110996 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.index = range(len(df))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看缺失值的数量，确保数据集中已经没有缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points      0\n",
       "price       0\n",
       "province    0\n",
       "region_1    0\n",
       "region_2    0\n",
       "variety     0\n",
       "winery      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 找出频繁模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 将数据集转换为指定格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "for i in range(1,df.iloc[:,0].size):  #行数\n",
    "    line = []\n",
    "    line.append(\"points\" + '='+ str(df.loc[i,'points']))\n",
    "    if(0<=df.loc[i,'price']<50):\n",
    "        line.append(\"price\" + '='+ 'price_0_50')\n",
    "    elif(50<=df.loc[i,'price']<100):\n",
    "        line.append(\"price\" + '='+ 'price_50_100')\n",
    "    elif(100<=df.loc[i,'price']<150):\n",
    "        line.append(\"price\" + '='+ 'price_100_150')\n",
    "    else:\n",
    "        line.append(\"price\" + '='+ 'price_150')\n",
    "    line.append(\"province\" + '='+ str(df.loc[i,'province']))\n",
    "    line.append(\"region_1\" + '='+ str(df.loc[i,'region_1']))\n",
    "    line.append(\"region_2\" + '='+ str(df.loc[i,'region_2']))\n",
    "    line.append(\"variety\" + '='+ str(df.loc[i,'variety']))\n",
    "    line.append(\"winery\" + '='+ str(df.loc[i,'winery']))\n",
    "    transactions.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 输出频繁项集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from efficient_apriori import apriori\n",
    "# itemsets,rules = apriori(transactions, min_support=0.5, min_confidence=1)\n",
    "# print(itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):  # 产生单个item的集合\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "\n",
    "    C1.sort()\n",
    "    return map(frozenset, C1)  # 给C1.list每个元素执行函数\n",
    "\n",
    "\n",
    "def scanD(D, ck, minSupport):  # dataset,a list of candidate set,最小支持率 支持度计数\n",
    "\n",
    "    ssCnt = {}\n",
    "    # temp_D = list(D)\n",
    "    numItem = float(len(D))\n",
    "    temp_ck = list(ck)\n",
    "    for tid in D:\n",
    "        for can in temp_ck:\n",
    "            if can.issubset(tid):\n",
    "                if can not in ssCnt:\n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        if numItem == 0:\n",
    "            continue\n",
    "        support = ssCnt[key] / numItem\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)\n",
    "            supportData[key] = support\n",
    "    return retList, supportData  # 返回频繁k项集，相应支持度\n",
    "\n",
    "\n",
    "def aprioriGen(Lk, k):  # create ck(k项集)\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(Lk[i])[:k - 2]\n",
    "            L2 = list(Lk[j])[:k - 2]\n",
    "            L1.sort()\n",
    "            L2.sort()  # 排序\n",
    "            if L1 == L2:  # 比较i,j前k-1个项若相同，和合并它俩\n",
    "                retList.append(Lk[i] | Lk[j])  # 加入新的k项集 | stanf for union\n",
    "    return retList # ck\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet) # c1 = return map\n",
    "    # D = map(set, dataSet) # D = map\n",
    "    D = dataSet\n",
    "    L1, supportData = scanD(D, C1, minSupport)  # 利用k项集生成频繁k项集（即满足最小支持率的k项集）\n",
    "    itemsets = [L1]  # itemsets保存所有频繁项集\n",
    "\n",
    "    k = 2\n",
    "    while (len(itemsets[k - 2]) > 0):  # 直到频繁k-1项集为空\n",
    "        Ck = aprioriGen(itemsets[k - 2], k)  # 利用频繁k-1项集 生成k项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport)\n",
    "        supportData.update(supK)  # 保存新的频繁项集与其支持度\n",
    "        itemsets.append(Lk)  # 保存频繁k项集\n",
    "        k += 1\n",
    "    return itemsets, supportData  # 返回所有频繁项集，与其相应的支持率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset({'price=price_0_50'}), frozenset({'province=California'})], [frozenset({'price=price_0_50', 'province=California'})], []]\n",
      "{frozenset({'province=California'}): 0.7036352988873372, frozenset({'price=price_0_50'}): 0.8116671922158656, frozenset({'price=price_0_50', 'province=California'}): 0.5541871255461958}\n"
     ]
    }
   ],
   "source": [
    "itemsets, supdata = apriori(transactions)\n",
    "print(itemsets)\n",
    "print(supdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 输出关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = []\n",
    "    lift = []\n",
    "    file = open(\"generate_rules.txt\",\"a\",encoding = \"utf-8\")\n",
    "    for conseq in H:  # 后件中的每个元素\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            file.write(str(freqSet - conseq)+\"-->\"+str(conseq)+\" support:\"+str(supportData[freqSet])+\" conf:\"+str(conf)+'\\n')\n",
    "            brl.append((freqSet - conseq, conseq, supportData[freqSet], conf))  # 添加入规则集中\n",
    "            prunedH.append(conseq)  # 添加入被修剪过的H中\n",
    "    file.close()\n",
    "    return prunedH\n",
    "\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    m = len(H[0])  # H是一系列后件长度相同的规则，所以取H0的长度即可\n",
    "    if (len(freqSet) > m + 1):\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    bigRuleList = []  # 存储规则\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(frozenset({'province=California'}), frozenset({'price=price_0_50'}), 0.5541871255461958, 0.7876056338028169), (frozenset({'price=price_0_50'}), frozenset({'province=California'}), 0.5541871255461958, 0.68277630395933)]\n"
     ]
    }
   ],
   "source": [
    "rules = generateRules(itemsets, supdata, minConf=0.5)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 使用lift进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_eval(rules, suppData): # lift evaluation\n",
    "    # lift(A, B) = P(A交B) / (P(A) * P(B)) = P(A) * P(B | A) / (P(A) * P(B)) = P(B | A) / P(B) = confidence(A— > B) / support(B) = confidence(B— > A) / support(A)\n",
    "    lift = []\n",
    "    for rule in rules:\n",
    "        freqSet_conseq = rule[0]\n",
    "        conseq = rule[1]\n",
    "        lift_val = float(rule[3]) / float(suppData[rule[1]])\n",
    "        lift.append([freqSet_conseq,conseq,lift_val])\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset({'province=California'}), frozenset({'price=price_0_50'}), 0.9703553887063487], [frozenset({'price=price_0_50'}), frozenset({'province=California'}), 0.9703553887063487]]\n"
     ]
    }
   ],
   "source": [
    "lifts = lift_eval(rules, supdata)\n",
    "print(lifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 使用卡方进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "x, y = transactions.data, transactions.target\n",
    "# result=mutual_info_classif(x,y,random_state=666)\n",
    "#mutual_info_classif是有一定的随机性的\n",
    "result=mutual_info_classif(x,y)\n",
    "#返回每个特征与标签的互信息估计量\n",
    "result\n",
    "#筛选出来互 信息量估计量 最大的前2个特征\n",
    "x_new = SelectKBest(mutual_info_classif, k=2).fit_transform(x, y)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过预处理后，保留的葡萄酒数据均为us的数据。\n",
    "\n",
    "从频繁项集和关联规则的结果可以看出，几乎所有的葡萄酒价格都在0到50之间，并且大多数的葡萄酒都是来自California省。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.可视化\n",
    "可视化部分包含在代码中"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcb2f34f5ce52af1333970cd33d78013a3c2b0f764a6569c50df1e95fcefba89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
